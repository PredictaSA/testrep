{"cells": [{"metadata": {"id": "b50b0dfc-2764-4419-88f9-3e6df6652c6a"}, "cell_type": "markdown", "source": "## Prompt Lab Challenge Exercises Notebook"}, {"metadata": {"id": "22801892-5c22-43da-962c-8eb3a9ef7b2c"}, "cell_type": "markdown", "source": "Welcome to the second prompt lab in the bootcamp series, you should have completed lab 1 and the exercises follow on from those. If you completed all the exercises in Lab 1 you should find most of the exercises here straightforward\n\nThis notebook is a template with all the exercises and indications of what the output should look like if you do a good job with the prompts.\n\nBefore you start you should have a Python environment with the necessary libraries installed as indicated in the intro lab, you will also need a .env file with: \n- your IBM Cloud API key\n- the IBM Cloud regional URL (eg, https://us-south.ml.cloud.ibm.com)\n- the project ID associated with your WatsonX project (required by the WML Python SDK)\n\nIt should take you about 30-45 min to walk through the exercises self paced\n\nGood luck and make sure you compare your answers with the model solutions\n"}, {"metadata": {"id": "9a8675ba-4bf9-4022-8c47-0a69fcff2e32"}, "cell_type": "code", "source": "import os\nfrom dotenv import load_dotenv\nfrom ibm_watson_machine_learning.foundation_models import Model\nfrom ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams", "execution_count": 1, "outputs": []}, {"metadata": {"id": "94faa91a-44da-417e-863a-74bbb7ca20c3"}, "cell_type": "markdown", "source": "2. Load credentials for Watsonx.ai (note refer to lab explaining how to do this if necessary)\n    - you should have a .env file with your IBM Cloud API key, eg API_KEY=xxx\n    - you should have a .env with the IBM Cloud regional url, eg IBM_CLOUD_URL=https://us-south.ml.cloud.ibm.com\n    - you should have a .env with the associated WatsonX project ID, eg PROJECT_ID=xxx"}, {"metadata": {"id": "412bc9e6-a555-44f8-8160-09ae0250d2b3"}, "cell_type": "code", "source": "#config Watsonx.ai environment\nload_dotenv()\napi_key = os.getenv(\"API_KEY\", None)\nibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", None)\nproject_id = os.getenv(\"PROJECT_ID\", None)\nif api_key is None or ibm_cloud_url is None or project_id is None:\n    print(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\nelse:\n    creds = {\n        \"url\": ibm_cloud_url,\n        \"apikey\": api_key \n    }", "execution_count": 2, "outputs": []}, {"metadata": {"id": "18f76ae0-1445-47d5-9e4d-9c776db82d6c"}, "cell_type": "markdown", "source": "Helper function for text generation with the [WML Python SDK](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html) for foundation models."}, {"metadata": {"id": "4608c115-aa23-499f-9564-502da24ffd78"}, "cell_type": "code", "source": "def send_to_watsonxai(prompts,\n                    model_name=\"google/flan-ul2\",\n                    decoding_method=\"greedy\",\n                    max_new_tokens=100,\n                    min_new_tokens=30,\n                    temperature=1.0,\n                    repetition_penalty=2.0\n                    ):\n    '''\n   helper function for sending prompts and params to Watsonx.ai\n    \n    Args:  \n        prompts:list list of text prompts\n        decoding:str Watsonx.ai parameter \"sample\" or \"greedy\"\n        max_new_tok:int Watsonx.ai parameter for max new tokens/response returned\n        temperature:float Watsonx.ai parameter for temperature (range 0>2)\n        repetition_penalty:float Watsonx.ai parameter for repetition penalty (range 1.0 to 2.0)\n\n    Returns: None\n        prints response\n    '''\n\n    assert not any(map(lambda prompt: len(prompt) < 1, prompts)), \"make sure none of the prompts in the inputs prompts are empty\"\n\n    # Instantiate parameters for text generation\n    model_params = {\n        GenParams.DECODING_METHOD: decoding_method,\n        GenParams.MIN_NEW_TOKENS: min_new_tokens,\n        GenParams.MAX_NEW_TOKENS: max_new_tokens,\n        GenParams.RANDOM_SEED: 42,\n        GenParams.TEMPERATURE: temperature,\n        GenParams.REPETITION_PENALTY: repetition_penalty,\n    }\n\n\n    # Instantiate a model proxy object to send your requests\n    model = Model(\n        model_id=model_name,\n        params=model_params,\n        credentials=creds,\n        project_id=project_id)\n\n\n    for prompt in prompts:\n        print(model.generate_text(prompt))\n", "execution_count": 3, "outputs": []}, {"metadata": {"id": "7727779b-ff82-46bb-a46d-2140672b0a7d"}, "cell_type": "markdown", "source": "#### Note that Q1 is challenging - consider doing it last in the lab\n#### Q1) Basic inference: A patients a1c level determines their diabetes status, the rules are as follows:\n\n - less than 5.7 no diabetes\n - between 5.7 and 6.5 pre-diabetes\n - greater than 6.5 diabetic.\n\nWrite a prompt to return just the diabetes status from the following 3 test cases:\n\n1)\tThe patients a1c is 5.5 which is good considering his other risk factors.\n2)\tFrom the last lab report I noted the A1c is 6.4 so we need to put her on Ozempic.\n3)\tShe mentioned her A1c is 8 according to her blood work about 3 years ago.\n\nBonus 1: How could you improve the inference given the other information in the sentences?\n\nBonus 2: how would you approach extracting the diabetes status based on patient notes without A1C values and what would you need to watch out for? (hint: maybe they are talking about family history of disease or other complications)\n"}, {"metadata": {"id": "cde402f5-7bb9-4a35-91b3-6752b9f77e71"}, "cell_type": "code", "source": "#Q1 ENTER YOUR MODEL PARAMS HERE - MAKE SURE IT WORKS WITH ALL 3 EXAMPLES ABOVE\nprompt = #complete your prompt here\nresponse = send_to_watsonxai(prompts=[prompt]) ", "execution_count": 5, "outputs": [{"name": "stdout", "output_type": "stream", "text": ". [1] The first of these is the so-called \"separate existence\" doctrine, which holds that an individual'[nonexistence or inability to perform certain functions) cannot be held legally responsible for his/her failure (or lack thereof).\n"}]}, {"metadata": {"id": "7575e182-01d8-486e-9419-0ed86df1b796"}, "cell_type": "code", "source": "# Product Review for Questions  2-6\nreview = \"\"\"Needed a nice lamp for my bedroom, and this one had \\\nadditional storage and not too high of a price point. \\\nGot it fast.  The string to our lamp broke during the \\\ntransit and the company happily sent over a new one. \\\nCame within a few days as well. It was easy to put \\\ntogether.  I had a missing part, so I contacted their \\\nsupport and they very quickly got me the missing piece! \\\nLumina seems to me to be a great company that cares \\\nabout their customers and products!!\"\"\"", "execution_count": 11, "outputs": []}, {"metadata": {"id": "3e61748c-add7-4ecc-9faf-4a9be44704bd"}, "cell_type": "markdown", "source": "#### Q2) write a prompt to return the sentiment of the review\nTarget sentiment = positive"}, {"metadata": {"id": "f3a4a3b3-4780-42e9-ac5c-3cb3ee708a44"}, "cell_type": "code", "source": "#Q2 Code - enter prompt and parameters in this cell\nprompt = #Complete your prompt here \nresponse = send_to_watsonxai(prompts=[prompt])", "execution_count": 12, "outputs": [{"name": "stdout", "output_type": "stream", "text": ". [1] The first of these is the so-called \"separate existence\" doctrine, which holds that an individual'[nonexistence or inability to perform certain functions) cannot be held legally responsible for his/her failure (or lack thereof).\n"}]}, {"metadata": {"id": "633ccd38-5f78-4722-9de8-d7291af4ccb8"}, "cell_type": "markdown", "source": "#### Q3) extract the emotions the reviewer expressed, return answer as a comma separated list\nTarget emotions = satisfied, happy, cared for, great company, product!"}, {"metadata": {"id": "e9ccd1cd-ba52-422c-b077-7f56c9699f1a"}, "cell_type": "code", "source": "prompt = \" \"\nresponse = send_to_watsonxai(prompts=[prompt])", "execution_count": 13, "outputs": [{"name": "stdout", "output_type": "stream", "text": ". [1] The first of these is the so-called \"separate existence\" doctrine, which holds that an individual'[nonexistence or inability to perform certain functions) cannot be held legally responsible for his/her failure (or lack thereof).\n"}]}, {"metadata": {"id": "8b428efe-578c-40c4-ae95-d2b5a1e3e6ad"}, "cell_type": "markdown", "source": "#### Q4) Is the reviewer expressing anger, answer \u201cyes\u201d or \u201cno\u201d \u2013 test with your own example including anger to ensure it works in both cases.\nTarget answer = no"}, {"metadata": {"id": "2017555b-4588-48cc-996a-27b5dc0a07b2"}, "cell_type": "code", "source": "prompt = #Complete your prompt here\nresponse = send_to_watsonxai(prompts=[prompt])\nprint(response)", "execution_count": 14, "outputs": [{"name": "stdout", "output_type": "stream", "text": ". [1] The first of these is the so-called \"separate existence\" doctrine, which holds that an individual'[nonexistence or inability to perform certain functions) cannot be held legally responsible for his/her failure (or lack thereof).\nNone\n"}]}, {"metadata": {"id": "7161b0a4-3fb2-475d-bef2-1eeb5e78f2d4"}, "cell_type": "markdown", "source": "#### Q5) Extract the item purchased and the company name, return as JSON format\nTarget answer = Item[lamp], Brand[Lumina]"}, {"metadata": {"id": "94617c5c-8d0e-4495-b20f-63f4475a3e18"}, "cell_type": "code", "source": "prompt = f\"\"\"\nIdentify the following items from the review text: \n- Item purchased by reviewer\n- Company that made the item\n\nThe review is delimited with triple backticks. \\\nFormat your response as a JSON object with \\\n\"Item\" and \"Brand\" as the keys. \nIf the information isn't present, use \"unknown\" \\\nas the value.\nMake your response as short as possible.\n  \nReview text: '''{review}'''\n\"\"\"\n\nprompt = #complete your prompt here\nresponse = send_to_watsonxai(prompts=[prompt])\nprint(response)", "execution_count": 15, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Failure during generate. (POST https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2022-08-01)\nStatus code: 400, body: {\"errors\":[{\"code\":\"invalid_request_entity\",\"message\":\"Missing json field TextGenRequest.input in request entity\"}],\"trace\":\"91d6ce96783c1dca8b6db1e178bce495\",\"status_code\":400}\n"}, {"ename": "ApiRequestFailure", "evalue": "Failure during generate. (POST https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2022-08-01)\nStatus code: 400, body: {\"errors\":[{\"code\":\"invalid_request_entity\",\"message\":\"Missing json field TextGenRequest.input in request entity\"}],\"trace\":\"91d6ce96783c1dca8b6db1e178bce495\",\"status_code\":400}", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mApiRequestFailure\u001b[0m                         Traceback (most recent call last)", "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mIdentify the following items from the review text: \u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m- Item purchased by reviewer\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mReview text: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mreview\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m response \u001b[39m=\u001b[39m send_to_watsonxai(prompts\u001b[39m=\u001b[39;49m[prompt])\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(response)\n", "Cell \u001b[0;32mIn[4], line 44\u001b[0m, in \u001b[0;36msend_to_watsonxai\u001b[0;34m(prompts, model_name, decoding_method, max_new_tokens, min_new_tokens, temperature, repetition_penalty)\u001b[0m\n\u001b[1;32m     36\u001b[0m model \u001b[39m=\u001b[39m Model(\n\u001b[1;32m     37\u001b[0m     model_id\u001b[39m=\u001b[39mmodel_name,\n\u001b[1;32m     38\u001b[0m     params\u001b[39m=\u001b[39mmodel_params,\n\u001b[1;32m     39\u001b[0m     credentials\u001b[39m=\u001b[39mcreds,\n\u001b[1;32m     40\u001b[0m     project_id\u001b[39m=\u001b[39mproject_id)\n\u001b[1;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39;49mgenerate_text(prompt))\n", "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/ibm_watson_machine_learning/foundation_models/model.py:191\u001b[0m, in \u001b[0;36mModel.generate_text\u001b[0;34m(self, prompt, params)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_text\u001b[39m(\u001b[39mself\u001b[39m, prompt, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    170\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Given a text prompt as input, and parameters the selected model (model_id)\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m    will generate a completion text as generated_text.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt\u001b[39m=\u001b[39;49mprompt, params\u001b[39m=\u001b[39;49mparams)[\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m'\u001b[39m]\n", "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/ibm_watson_machine_learning/foundation_models/model.py:167\u001b[0m, in \u001b[0;36mModel.generate\u001b[0;34m(self, prompt, params)\u001b[0m\n\u001b[1;32m    160\u001b[0m     payload[\u001b[39m'\u001b[39m\u001b[39mspace_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mdefault_space_id\n\u001b[1;32m    162\u001b[0m response_scoring \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(\n\u001b[1;32m    163\u001b[0m         url\u001b[39m=\u001b[39mgenerate_text_url,\n\u001b[1;32m    164\u001b[0m         json\u001b[39m=\u001b[39mpayload,\n\u001b[1;32m    165\u001b[0m         headers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39m_get_headers())\n\u001b[0;32m--> 167\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_response(\u001b[39m200\u001b[39;49m, \u001b[39mu\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgenerate\u001b[39;49m\u001b[39m'\u001b[39;49m, response_scoring)\n", "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/ibm_watson_machine_learning/wml_resource.py:64\u001b[0m, in \u001b[0;36mWMLResource._handle_response\u001b[0;34m(self, expected_status_code, operationName, response, json_response)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mtext\n\u001b[1;32m     63\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mraise\u001b[39;00m ApiRequestFailure(\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFailure during \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(operationName), response)\n", "\u001b[0;31mApiRequestFailure\u001b[0m: Failure during generate. (POST https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2022-08-01)\nStatus code: 400, body: {\"errors\":[{\"code\":\"invalid_request_entity\",\"message\":\"Missing json field TextGenRequest.input in request entity\"}],\"trace\":\"91d6ce96783c1dca8b6db1e178bce495\",\"status_code\":400}"]}]}, {"metadata": {"id": "0462e8a3-bc14-4261-a4ae-23fcb72bb7a8"}, "cell_type": "markdown", "source": "#### Q6) Can you combine 3-6 in a single prompt and return JSON with: Sentiment (negative or positive), Anger (yes/no), Product, Company\nTarget answer = Sentiment[positive], Anger[false], Item[lamp], Brand[Lumina]"}, {"metadata": {"id": "73a3f516-bf4a-4131-9838-e8001df517c7"}, "cell_type": "code", "source": "prompt = #Complete your prompt here \nresponse = send_to_watsonxai(prompts=[prompt])\nprint(response)", "execution_count": null, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Sentiment[positive], Anger[false], Item[lamp], Brand[Lumina]\n"}]}, {"metadata": {"id": "1a9bdbb5-5b39-4533-954b-65835b74d2d2"}, "cell_type": "markdown", "source": "#### Q7) summarize the following product review\nExample summary = My daughter loves it!  It's soft and  super cute, and its face has a friendly look. It's  a bit small for what I paid though."}, {"metadata": {"id": "ce3e7e13-c96b-4946-ad39-6895ac511be3"}, "cell_type": "code", "source": "review = \"\"\"Got this panda plush toy for my daughter's birthday, \\\nwho loves it and takes it everywhere. It's soft and \\ \nsuper cute, and its face has a friendly look. It's \\ \na bit small for what I paid though. I think there \\ \nmight be other options that are bigger for the \\ \nsame price. It arrived a day earlier than expected, \\ \nso I got to play with it myself before I gave it to her.\"\"\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "8e343514-478d-47cd-ab99-ffccb89c4ca5"}, "cell_type": "code", "source": "prompt = #Complete your prompt here\nresponse = send_to_watsonxai(prompts=[prompt])\nprint(response) ", "execution_count": null, "outputs": [{"name": "stdout", "output_type": "stream", "text": "My daughter loves it!  It's soft and  super cute, and its face has a friendly look. It's  a bit small for what I paid though.\n"}]}, {"metadata": {"id": "4ac1dc2b-a7d2-48a6-b542-202e13bcb538"}, "cell_type": "markdown", "source": "#### Q8) Summarize the same product review from the perspective of the shipping department\nExample summary = It arrived a day earlier than expected, so I got to play with it myself before I gave it  to her. "}, {"metadata": {"id": "7dcb8172-9eee-40b2-ac9a-03fda3be8079"}, "cell_type": "code", "source": "#concise wrt feedback shipping\nprompt = #Complete your prompt here\nresponse = send_to_watsonxai(prompts=[prompt])\nprint(response)", "execution_count": null, "outputs": [{"name": "stdout", "output_type": "stream", "text": "It arrived a day earlier than expected,  so I got to play with it myself before I gave it  to her. \n"}]}, {"metadata": {"id": "747d0020-0ee0-468b-a315-a56bc5151d3c"}, "cell_type": "markdown", "source": "#### Q9) Summarize the review from the perspective of pricing and value\nExample summary = It's a bit small for what I paid though. I think there might be other options that are bigger for the same price"}, {"metadata": {"id": "5e41dc29-7e19-4564-bf61-a3bb23d47c1a"}, "cell_type": "code", "source": "#feedback pricing works - concise\nprompt = #Complete your prompt here \nresponse = send_to_watsonxai(prompts=[prompt])\nprint(response)", "execution_count": null, "outputs": [{"name": "stdout", "output_type": "stream", "text": "It's a bit small for what I paid though. I think there  might be other options that are bigger for the  same price\n"}]}, {"metadata": {"id": "4f52386f-fbdc-4dc0-bab2-99d030693eb4"}, "cell_type": "markdown", "source": "#### Q10)\tPII removal. Given the following email, write a prompt to remove the PII (eg names, emails etc) (Hint: you may need to use 1-2 shot technique)"}, {"metadata": {"id": "68f008f9-5687-4de1-92e9-6444127da68d"}, "cell_type": "code", "source": "email = \"\"\"\nHi John,\\\n\nI'm writing to you because I noticed you recently purchased a new car. I'm a salesperson\\\nat a local dealership (Cheap Dealz), and I wanted to let you know that we have a great deal on a new\\\ncar. If you're interested, please let me know.\\\n\nThanks,\\\n\nJimmy Smith\\\n\nPhone: 410-805-2345\\\nEmail: jimmysmith@cheapdealz.com\\\n\"\"\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "d79e2fe0-feb6-408b-9ed6-b420f1930315"}, "cell_type": "markdown", "source": "Hint - use prompt template or manually construct the prompt with f strings (look up in documentation if unsure)"}, {"metadata": {"id": "4e3e3188-abfd-444e-ac0c-1d29c2001af0"}, "cell_type": "code", "source": "prompt = #Complete your prompt here \nresponse = send_to_watsonxai(prompts=[prompt])\nprint(response)", "execution_count": 16, "outputs": [{"name": "stdout", "output_type": "stream", "text": ". [1] The first of these is the so-called \"separate existence\" doctrine, which holds that an individual'[nonexistence or inability to perform certain functions) cannot be held legally responsible for his/her failure (or lack thereof).\nNone\n"}]}, {"metadata": {"id": "b952616a-6308-44e7-a75a-f6f3e21cde6b"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}